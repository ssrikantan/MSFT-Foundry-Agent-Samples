# Azure AI Foundry Configuration
# Copy this file to .env and fill in your values

# Required for all scripts
# The endpoint URL for your AI Foundry project
AZURE_AI_FOUNDRY_PROJECT_ENDPOINT="https://your-resource.services.ai.azure.com/api/projects/your-project-name"

# Required for foundry-client-app.py and ops/create-agent.py
# The name of your deployed model (e.g., gpt-4o, gpt-4.1-mini)
AZURE_AI_FOUNDRY_MODEL_DEPLOYMENT_NAME=gpt-4o

# Required for foundry-agent-app.py
# The name of the agent configured in Azure AI Foundry portal
AZURE_AI_FOUNDRY_AGENT_NAME=your-agent-name

# Required for foundry-app-client.py (Published Agent Application)
# The endpoint URL for the published Agent Application
# Format: https://<resource>.services.ai.azure.com/api/projects/<project>/applications/<app-name>/protocols/openai
AZURE_AI_FOUNDRY_APP_ENDPOINT="https://your-resource.services.ai.azure.com/api/projects/your-project/applications/your-app-name/protocols/openai"

# Required for structured-output-client.py (Structured Output Test Agent)
# Endpoint for the published agent configured with JSON schema structured output
AZURE_AI_FOUNDRY_STRUCTURED_OUTPUT_APP_ENDPOINT="https://your-resource.services.ai.azure.com/api/projects/your-project/applications/structured-output-test-agent/protocols/openai"

# =============================================================================
# Knowledge Base MCP Configuration (for agents with Knowledge Base tools)
# =============================================================================
# MCP endpoint for your Azure AI Search Knowledge Base
# Format: https://<search-service>.search.windows.net/knowledgebases/<kb-name>/mcp?api-version=2025-11-01-Preview
AZURE_AI_SEARCH_KB_MCP_ENDPOINT=""

# =============================================================================
# Logging Configuration
# =============================================================================
# Log level for streaming client output
# Options: DEBUG (all events), INFO (tool calls only), WARN (errors only), OFF (no logging)
LOG_LEVEL=INFO

# Project connection name for authentication to the Knowledge Base
AZURE_AI_SEARCH_KB_CONNECTION_NAME=""

# Server label used in the agent's MCP tool configuration
AZURE_AI_SEARCH_KB_SERVER_LABEL="knowledge-base"

# MCP Tool Approval Setting
# Set to "never" for published Agent Applications (required - they don't support approval flow)
# Set to "always" if you want manual approval for each tool call
# Default: "never"
AZURE_AI_MCP_REQUIRE_APPROVAL="never"

# =============================================================================
# Tracing Configuration (Optional but RECOMMENDED)
# =============================================================================
# Tracing is automatically configured when Application Insights is enabled in 
# your Foundry project. The connection string is retrieved automatically.
#
# IMPORTANT: Content capture is now enabled programmatically in the app code.
# The app sets AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED=true before
# importing the Azure SDK, which is the correct way per Microsoft docs:
# https://learn.microsoft.com/azure/ai-foundry/how-to/develop/trace-agents-sdk
#
# Legacy env vars (may still be needed for some OpenTelemetry instrumentors):
# OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT=true
#
# To disable automatic tracing instrumentation, set:
# AZURE_TRACING_GEN_AI_INSTRUMENT_RESPONSES_API=false